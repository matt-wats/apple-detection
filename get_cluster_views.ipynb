{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_points = np.load(\"apple_points3d.npy\")\n",
    "pts3d = color_points[:,:3]\n",
    "rgb3d = color_points[:,-3:]\n",
    "\n",
    "with open(\"./0/images.txt\", \"r\") as f:\n",
    "    temp_images = f.readlines()[4:][::2]\n",
    "img_ids = np.array([x.split(\" \")[0] for x in temp_images], dtype=np.int16)\n",
    "poses = np.array([x.split(\" \")[1:8] for x in temp_images], dtype=np.float32)\n",
    "\n",
    "with open(\"./0/cameras.txt\", \"r\") as f:\n",
    "    temp_cameras = f.readlines()[-1]\n",
    "cam_params = np.array(temp_cameras.split(\" \")[-4:], dtype=np.float32)\n",
    "\n",
    "con = sqlite3.connect(\"./database.db\")\n",
    "cur = con.cursor()\n",
    "img_dict = dict()\n",
    "for row in cur.execute(\"SELECT * FROM IMAGES\"):\n",
    "    img_dict[row[0]] = row[1]\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [img_dict[idx] for idx in img_ids]\n",
    "images_path = \"./images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaled_points = StandardScaler().fit_transform(pts3d)\n",
    "model = DBSCAN(eps=0.1, min_samples=5)\n",
    "labels = model.fit_predict(scaled_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = []\n",
    "for i in range(labels.max()):\n",
    "    curr_indices = (labels == i)\n",
    "    cluster = pts3d[curr_indices]\n",
    "    clusters.append(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:00<00:00, 282.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "cluster_images = []\n",
    "\n",
    "# for each cluster\n",
    "for cluster in tqdm(clusters):\n",
    "    # calculate position of cluster in each pose\n",
    "    cluster_instances = []\n",
    "    for i in range(len(filenames)):\n",
    "        extrinsic = get_extrinsic_matrix(poses[i])\n",
    "        K = get_K_matrix(cam_params)\n",
    "\n",
    "        cam_pts = get_camera_view(cluster, extrinsic)\n",
    "        pixel_pts = get_image_view(cam_pts, K)\n",
    "        inliers = get_in_view_points(pixel_pts)\n",
    "\n",
    "        if inliers.all():\n",
    "            rmin, cmin = pixel_pts[:,:2].min(axis=0)\n",
    "            rmax, cmax = pixel_pts[:,:2].max(axis=0)\n",
    "            bbox = np.int32(np.round(np.array([rmin, cmin, rmax, cmax])))\n",
    "\n",
    "            filename = filenames[i]\n",
    "\n",
    "            cluster_instances.append([filename, bbox])\n",
    "    \n",
    "    cluster_images.append(cluster_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded updated model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Using pretrained weights:\n",
    "weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "model = resnet50(weights=weights).to(device)\n",
    "model.fc = torch.nn.Linear(2048, 7, bias=True).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"resnet.pt\"))\n",
    "model.eval()\n",
    "\n",
    "print(\"Loaded updated model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:38<00:00,  2.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.io import read_image\n",
    "from torchvision import transforms as T\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((224,224), antialias=True),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "cluster_counts = []\n",
    "\n",
    "for cluster in tqdm(cluster_images):\n",
    "    counts = []\n",
    "    for img_name, bbox in cluster:\n",
    "        img_path = os.path.join(images_path, img_name)\n",
    "        image = read_image(img_path) / 255.0\n",
    "        image = image[:,bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "        image = transform(image)\n",
    "        image = image.unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(image.to(device))\n",
    "            counts.append(pred.argmax().item())\n",
    "    cluster_counts.append(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_cluster_count = [np.median(sorted(counts)[-3:]) for counts in cluster_counts if len(counts) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303.0\n"
     ]
    }
   ],
   "source": [
    "total = sum(per_cluster_count)\n",
    "print(total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
